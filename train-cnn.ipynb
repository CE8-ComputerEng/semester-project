{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, loggers\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torchmetrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsummary import summary\n",
    "import glob\n",
    "import tqdm\n",
    "from dataset import SpectrogramDataset\n",
    "import utils\n",
    "import dataimporter\n",
    "from utils import plot_confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(pl.LightningModule):\n",
    "    def __init__(self, classes):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        \n",
    "        self.classes = classes\n",
    "        num_classes = len(classes)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 5 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.confusion_matrix = torchmetrics.ConfusionMatrix(num_classes=num_classes, task='multiclass')\n",
    "        \n",
    "        self.test_confusion_matrix = np.zeros((num_classes, num_classes))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.maxpool(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 128 * x.shape[2] * x.shape[3])\n",
    "        \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        \n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        _, predicted = torch.max(y_hat, 1)\n",
    "        accuracy = (predicted == y).sum().item() / len(y)\n",
    "        self.log('train_acc', accuracy, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        \n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('val_loss', loss)\n",
    "        \n",
    "        _, predicted = torch.max(y_hat, 1)\n",
    "        accuracy = (predicted == y).sum().item() / len(y)\n",
    "        self.log('val_acc', accuracy)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        \n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('test_loss', loss)\n",
    "        \n",
    "        _, predicted = torch.max(y_hat, 1)\n",
    "        accuracy = (predicted == y).sum().item() / len(y)\n",
    "        self.log('test_acc', accuracy)\n",
    "        \n",
    "        confusion_matrix = self.confusion_matrix(predicted, y)\n",
    "        self.test_confusion_matrix += confusion_matrix.cpu().numpy()\n",
    "        \n",
    "    def on_test_epoch_end(self):\n",
    "        plot_confusion_matrix(self.test_confusion_matrix, self.classes, filename='confusion_matrix.png')\n",
    "        \n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n",
    "        x = batch\n",
    "        y_hat = self(x)\n",
    "        \n",
    "        _, predicted = torch.max(y_hat, 1)\n",
    "        return predicted\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NPDATAPATH = 'data/measurment-2/data.npy'\n",
    "NPLABELPATH = 'data/measurment-2/labels.npy'\n",
    "DATAPATH = 'data/measurment-2/clips/wav/'\n",
    "LABELPATH = 'data/measurment-2/clips/txt/'\n",
    "data_np, labels_np, data_size = dataimporter.import_data(NPDATAPATH, NPLABELPATH, DATAPATH, LABELPATH)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just for fun: spectrogram plot loop\n",
    "Uncomment if you want to see the plot of the spectrograms in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_audio_spectogram(data_np[99])\n",
    "#%matplotlib qt\n",
    "#utils.loop_plot_audio_spectogram(data_np)\n",
    "#%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_RATIO = 0.8\n",
    "VALIDATION_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "\n",
    "if TRAINING_RATIO + VALIDATION_RATIO + TEST_RATIO != 1:\n",
    "    raise ValueError('Training, validation, and test ratios must sum to 1.')\n",
    "\n",
    "train_size = int(TRAINING_RATIO * len(data_np))\n",
    "val_size = int(VALIDATION_RATIO * len(data_np))\n",
    "test_size = len(data_np) - train_size - val_size\n",
    "\n",
    "train_spectrograms, val_spectrograms, train_labels, val_labels = train_test_split(data_np, labels_np, test_size=val_size, random_state=42)\n",
    "train_spectrograms, test_spectrograms, train_labels, test_labels = train_test_split(train_spectrograms, train_labels, test_size=test_size, random_state=42)\n",
    "\n",
    "print('Training samples:', train_spectrograms.shape[0])\n",
    "print('Validation samples:', val_spectrograms.shape[0])\n",
    "print('Test samples:', test_spectrograms.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transforms for data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # Add more transforms here\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = SpectrogramDataset(train_spectrograms, train_labels, transform=transform)\n",
    "val_dataset = SpectrogramDataset(val_spectrograms, val_labels, transform=transforms.ToTensor())\n",
    "test_dataset = SpectrogramDataset(test_spectrograms, test_labels, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define classes, and summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['Background', 'Anomaly']\n",
    "\n",
    "model = CNNClassifier(classes=CLASSES)\n",
    "print(\"Data size: \", data_size)\n",
    "\n",
    "summary(model, (1 , data_size[0], data_size[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 30\n",
    "VERSION = 'cnn_v2_epoch-30-v2'\n",
    "\n",
    "accelerator = None\n",
    "if torch.cuda.is_available():\n",
    "    accelerator = 'gpu'\n",
    "elif torch.backends.mps.is_available():\n",
    "    accelerator = 'cpu'  # MPS is not implemented in PyTorch yet\n",
    "\n",
    "tb_logger = loggers.TensorBoardLogger('.', version=VERSION)\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_acc', mode='max', save_top_k=1, save_last=True, filename='best-{epoch}-{val_acc:.2f}')\n",
    "\n",
    "trainer = Trainer(accelerator=accelerator, max_epochs=MAX_EPOCHS, logger=tb_logger, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previously trained model\n",
    "CHECKPOINT_PATH = f'lightning_logs/{VERSION}/checkpoints/best-epoch=0-val_acc=1.00.ckpt'\n",
    "\n",
    "model = CNNClassifier.load_from_checkpoint(CHECKPOINT_PATH, classes=CLASSES)\n",
    "print(f'Model size: {os.path.getsize(CHECKPOINT_PATH) / 1e6} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, test_loader) # This not the challenge, test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms_to_predict = np.load('data/test.npy')\n",
    "\n",
    "print('Test spectrogram to predict shape:', spectrograms_to_predict.shape)\n",
    "print('Test spectrogram to predict dtype:', spectrograms_to_predict.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_predict_dataset = SpectrogramDataset(spectrograms_to_predict, transform=transforms.ToTensor())\n",
    "test_to_predict_loader = DataLoader(test_to_predict_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(model, test_to_predict_loader)\n",
    "predictions = np.concatenate(predictions).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('predictions.txt', predictions, delimiter='\\n', fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
